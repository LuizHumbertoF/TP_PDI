{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db80eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "importlib.reload(__import__('helpers'))\n",
    "from helpers import save_fewshot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f909b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'n_way': 3,           # Número de classes por episódio\n",
    "    'n_shot': 5,          # Exemplos de treino por classe\n",
    "    'n_query': 15,        # Exemplos de teste por classe\n",
    "    'n_episodes': 100,    # Número de episódios para avaliação\n",
    "    'model_name': 'deit_base_distilled_patch16_224',\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc25e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],   \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f8f3ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from collections import defaultdict\n",
    "\n",
    "dataset = datasets.ImageFolder(\n",
    "    root='/content/dataset/ham10000/all',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# mapa classe → índices\n",
    "class_to_indices = defaultdict(list)\n",
    "for idx, (_, label) in enumerate(dataset):\n",
    "    class_to_indices[label].append(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5277e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "def create_episode(\n",
    "    class_to_indices,\n",
    "    n_way=5,\n",
    "    n_shot=10,\n",
    "    n_query=15\n",
    "):\n",
    "    classes = random.sample(list(class_to_indices.keys()), n_way)\n",
    "\n",
    "    support_idx = []\n",
    "    query_idx = []\n",
    "\n",
    "    for c in classes:\n",
    "        indices = random.sample(\n",
    "            class_to_indices[c],\n",
    "            n_shot + n_query\n",
    "        )\n",
    "        support_idx += indices[:n_shot]\n",
    "        query_idx   += indices[n_shot:]\n",
    "\n",
    "    return support_idx, query_idx, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "061c9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_loaders(dataset, support_idx, query_idx):\n",
    "    support_loader = DataLoader(\n",
    "        Subset(dataset, support_idx),\n",
    "        batch_size=len(support_idx),\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    query_loader = DataLoader(\n",
    "        Subset(dataset, query_idx),\n",
    "        batch_size=len(query_idx),\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return support_loader, query_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83ebe2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_vit(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = imgs.to(next(model.parameters()).device)\n",
    "            feats = model(imgs)      # saída do DeiT sem head\n",
    "            features.append(feats)\n",
    "            labels.append(lbls)\n",
    "\n",
    "    return torch.cat(features), torch.cat(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67e83f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate_episode(\n",
    "    model,\n",
    "    dataset,\n",
    "    class_to_indices,\n",
    "    device,\n",
    "    n_way=5,\n",
    "    n_shot=10,\n",
    "    n_query=15\n",
    "):\n",
    "    support_idx, query_idx, classes = create_episode(\n",
    "        class_to_indices, n_way, n_shot, n_query\n",
    "    )\n",
    "\n",
    "    support_loader, query_loader = get_episode_loaders(\n",
    "        dataset, support_idx, query_idx\n",
    "    )\n",
    "\n",
    "    support_features, support_labels = extract_features_vit(\n",
    "        support_loader, model\n",
    "    )\n",
    "    query_features, query_labels = extract_features_vit(\n",
    "        query_loader, model\n",
    "    )\n",
    "\n",
    "    # normalização\n",
    "    support_features = F.normalize(support_features, p=2, dim=1)\n",
    "    query_features   = F.normalize(query_features, p=2, dim=1)\n",
    "\n",
    "    # remapeia rótulos para [0..n_way-1]\n",
    "    label_map = {c: i for i, c in enumerate(classes)}\n",
    "    support_labels = torch.tensor(\n",
    "        [label_map[int(l)] for l in support_labels],\n",
    "        device=device\n",
    "    )\n",
    "    query_labels = torch.tensor(\n",
    "        [label_map[int(l)] for l in query_labels],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # protótipos\n",
    "    prototypes = torch.zeros(n_way, support_features.size(1)).to(device)\n",
    "    for i in range(n_way):\n",
    "        prototypes[i] = support_features[support_labels == i].mean(0)\n",
    "    \n",
    "    # normalizar todos os protótipos\n",
    "    prototypes = F.normalize(prototypes, p=2, dim=1)\n",
    "\n",
    "    # similaridade\n",
    "    sims = torch.mm(query_features, prototypes.t())\n",
    "    preds = sims.argmax(dim=1)\n",
    "\n",
    "    acc = (preds == query_labels).float().mean().item()\n",
    "    return acc, preds.cpu().numpy(), query_labels.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c5c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformerDistilled(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Identity()\n",
       "  (head_dist): Identity()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "\n",
    "print(CONFIG['device'])\n",
    "model = timm.create_model(\n",
    "    CONFIG['model_name'],\n",
    "    pretrained=True,\n",
    "    num_classes=0\n",
    ")\n",
    "\n",
    "model = model.to(CONFIG['device'])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d428ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episódio 1: 86.67%\n",
      "Episódio 2: 44.44%\n",
      "Episódio 3: 82.22%\n",
      "Episódio 4: 68.89%\n",
      "Episódio 5: 77.78%\n",
      "Episódio 6: 84.44%\n",
      "Episódio 7: 68.89%\n",
      "Episódio 8: 62.22%\n",
      "Episódio 9: 86.67%\n",
      "Episódio 10: 82.22%\n",
      "Episódio 11: 68.89%\n",
      "Episódio 12: 64.44%\n",
      "Episódio 13: 53.33%\n",
      "Episódio 14: 64.44%\n",
      "Episódio 15: 62.22%\n",
      "Episódio 16: 75.56%\n",
      "Episódio 17: 66.67%\n",
      "Episódio 18: 40.00%\n",
      "Episódio 19: 55.56%\n",
      "Episódio 20: 71.11%\n",
      "Episódio 21: 46.67%\n",
      "Episódio 22: 68.89%\n",
      "Episódio 23: 53.33%\n",
      "Episódio 24: 62.22%\n",
      "Episódio 25: 73.33%\n",
      "Episódio 26: 53.33%\n",
      "Episódio 27: 66.67%\n",
      "Episódio 28: 60.00%\n",
      "Episódio 29: 62.22%\n",
      "Episódio 30: 64.44%\n",
      "Episódio 31: 62.22%\n",
      "Episódio 32: 57.78%\n",
      "Episódio 33: 75.56%\n",
      "Episódio 34: 73.33%\n",
      "Episódio 35: 62.22%\n",
      "Episódio 36: 62.22%\n",
      "Episódio 37: 80.00%\n",
      "Episódio 38: 64.44%\n",
      "Episódio 39: 48.89%\n",
      "Episódio 40: 55.56%\n",
      "Episódio 41: 66.67%\n",
      "Episódio 42: 84.44%\n",
      "Episódio 43: 57.78%\n",
      "Episódio 44: 64.44%\n",
      "Episódio 45: 66.67%\n",
      "Episódio 46: 37.78%\n",
      "Episódio 47: 51.11%\n",
      "Episódio 48: 73.33%\n",
      "Episódio 49: 73.33%\n",
      "Episódio 50: 57.78%\n",
      "\n",
      "Acurácia final: 65.07% ± 11.56%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "accuracies = []\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for ep in range(CONFIG['n_episodes']):\n",
    "    acc, preds, labels = evaluate_episode(\n",
    "        model,\n",
    "        dataset,\n",
    "        class_to_indices,\n",
    "        device,\n",
    "        n_way=CONFIG['n_way'],\n",
    "        n_shot=CONFIG['n_shot'],\n",
    "        n_query=CONFIG['n_query']\n",
    "    )\n",
    "    accuracies.append(acc)\n",
    "    all_predictions.extend(preds)\n",
    "    all_labels.extend(labels)\n",
    "    print(f\"Episódio {ep+1}: {acc*100:.2f}%\")\n",
    "\n",
    "mean_acc = np.mean(accuracies)\n",
    "std_acc  = np.std(accuracies)\n",
    "\n",
    "print(f\"\\nAcurácia final: {mean_acc*100:.2f}% ± {std_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d870b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Resultados salvos em: /content/drive/MyDrive/pdi/resultados/deit_prototypical_fewshot_3way_5shot_50ep\n",
      "============================================================\n",
      "Configuração: 3-way 5-shot (50 episódios)\n",
      "Acurácia: 65.07% ± 11.56%\n",
      "Precision (macro): 65.11%\n",
      "Recall (macro): 65.07%\n",
      "F1-Score (macro): 65.04%\n",
      "Arquivos gerados:\n",
      "  - config.json\n",
      "  - report.txt\n",
      "  - confusion_matrix.png\n",
      "  - predictions.json\n",
      "  - accuracy_per_episode.png\n",
      "  - accuracy_distribution.png\n",
      "  - accuracy_boxplot.png\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Salvar resultados do experimento\n",
    "exp_dir = save_fewshot_results(\n",
    "    experiment_name=\"deit_prototypical_fewshot\",\n",
    "    model_name=CONFIG['model_name'],\n",
    "    metric_name=\"Similaridade Cosine\",\n",
    "    normalization=\"Normalizacao L2\",\n",
    "    accuracies=accuracies,\n",
    "    n_way=CONFIG['n_way'],\n",
    "    n_shot=CONFIG['n_shot'],\n",
    "    n_query=CONFIG['n_query'],\n",
    "    n_episodes=CONFIG['n_episodes'],\n",
    "    device=CONFIG['device'],\n",
    "    all_predictions=all_predictions,\n",
    "    all_labels=all_labels\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
