{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "db80eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "importlib.reload(__import__('helpers'))\n",
    "from helpers import save_fewshot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f909b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'n_way': 3,           # N√∫mero de classes por epis√≥dio\n",
    "    'n_shot': 5,          # Exemplos de treino por classe\n",
    "    'n_query': 15,        # Exemplos de teste por classe\n",
    "    'n_episodes': 200,    # N√∫mero de epis√≥dios para avalia√ß√£o\n",
    "    'model_name': 'deit_base_distilled_patch16_224',\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc25e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],   \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f8f3ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from collections import defaultdict\n",
    "\n",
    "dataset = datasets.ImageFolder(\n",
    "    root='/content/drive/MyDrive/pdi/dataset/ham10000/all',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# mapa classe ‚Üí √≠ndices\n",
    "class_to_indices = defaultdict(list)\n",
    "for idx, (_, label) in enumerate(dataset):\n",
    "    class_to_indices[label].append(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5277e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "def create_episode(\n",
    "    class_to_indices,\n",
    "    n_way=5,\n",
    "    n_shot=10,\n",
    "    n_query=15\n",
    "):\n",
    "    classes = random.sample(list(class_to_indices.keys()), n_way)\n",
    "\n",
    "    support_idx = []\n",
    "    query_idx = []\n",
    "\n",
    "    for c in classes:\n",
    "        indices = random.sample(\n",
    "            class_to_indices[c],\n",
    "            n_shot + n_query\n",
    "        )\n",
    "        support_idx += indices[:n_shot]\n",
    "        query_idx   += indices[n_shot:]\n",
    "\n",
    "    return support_idx, query_idx, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "061c9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_loaders(dataset, support_idx, query_idx):\n",
    "    support_loader = DataLoader(\n",
    "        Subset(dataset, support_idx),\n",
    "        batch_size=len(support_idx),\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    query_loader = DataLoader(\n",
    "        Subset(dataset, query_idx),\n",
    "        batch_size=len(query_idx),\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return support_loader, query_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83ebe2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_vit(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = imgs.to(next(model.parameters()).device)\n",
    "            feats = model(imgs)      # sa√≠da do DeiT sem head\n",
    "            features.append(feats)\n",
    "            labels.append(lbls)\n",
    "\n",
    "    return torch.cat(features), torch.cat(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67e83f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate_episode(\n",
    "    model,\n",
    "    dataset,\n",
    "    class_to_indices,\n",
    "    device,\n",
    "    n_way=5,\n",
    "    n_shot=10,\n",
    "    n_query=15\n",
    "):\n",
    "    support_idx, query_idx, classes = create_episode(\n",
    "        class_to_indices, n_way, n_shot, n_query\n",
    "    )\n",
    "\n",
    "    support_loader, query_loader = get_episode_loaders(\n",
    "        dataset, support_idx, query_idx\n",
    "    )\n",
    "\n",
    "    support_features, support_labels = extract_features_vit(\n",
    "        support_loader, model\n",
    "    )\n",
    "    query_features, query_labels = extract_features_vit(\n",
    "        query_loader, model\n",
    "    )\n",
    "\n",
    "    # Guardar labels originais antes do remapeamento\n",
    "    original_query_labels = query_labels.cpu().numpy()\n",
    "\n",
    "    # normaliza√ß√£o\n",
    "    support_features = F.normalize(support_features, p=2, dim=1)\n",
    "    query_features   = F.normalize(query_features, p=2, dim=1)\n",
    "\n",
    "    # remapeia r√≥tulos para [0..n_way-1]\n",
    "    label_map = {c: i for i, c in enumerate(classes)}\n",
    "    support_labels = torch.tensor(\n",
    "        [label_map[int(l)] for l in support_labels],\n",
    "        device=device\n",
    "    )\n",
    "    query_labels_remapped = torch.tensor(\n",
    "        [label_map[int(l)] for l in query_labels],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # prot√≥tipos\n",
    "    prototypes = torch.zeros(n_way, support_features.size(1)).to(device)\n",
    "    for i in range(n_way):\n",
    "        prototypes[i] = support_features[support_labels == i].mean(0)\n",
    "    \n",
    "    # normalizar todos os prot√≥tipos\n",
    "    prototypes = F.normalize(prototypes, p=2, dim=1)\n",
    "\n",
    "    # similaridade\n",
    "    sims = torch.mm(query_features, prototypes.t())\n",
    "    preds_remapped = sims.argmax(dim=1)\n",
    "\n",
    "    # Acur√°cia do epis√≥dio (com labels remapeados)\n",
    "    acc = (preds_remapped == query_labels_remapped).float().mean().item()\n",
    "    \n",
    "    # Reverter predi√ß√µes para classes originais\n",
    "    original_preds = np.array([classes[int(p)] for p in preds_remapped.cpu().numpy()])\n",
    "    \n",
    "    return acc, preds_remapped.cpu().numpy(), query_labels_remapped.cpu().numpy(), original_preds, original_query_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "\n",
    "print(CONFIG['device'])\n",
    "model = timm.create_model(\n",
    "    CONFIG['model_name'],\n",
    "    pretrained=True,\n",
    "    num_classes=0\n",
    ")\n",
    "\n",
    "model = model.to(CONFIG['device'])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41d428ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epis√≥dio 1: 82.22%\n",
      "Epis√≥dio 2: 53.33%\n",
      "Epis√≥dio 3: 66.67%\n",
      "Epis√≥dio 4: 44.44%\n",
      "Epis√≥dio 5: 62.22%\n",
      "Epis√≥dio 6: 97.78%\n",
      "Epis√≥dio 7: 60.00%\n",
      "Epis√≥dio 8: 73.33%\n",
      "Epis√≥dio 9: 68.89%\n",
      "Epis√≥dio 10: 64.44%\n",
      "Epis√≥dio 11: 71.11%\n",
      "Epis√≥dio 12: 64.44%\n",
      "Epis√≥dio 13: 84.44%\n",
      "Epis√≥dio 14: 44.44%\n",
      "Epis√≥dio 15: 77.78%\n",
      "Epis√≥dio 16: 68.89%\n",
      "Epis√≥dio 17: 68.89%\n",
      "Epis√≥dio 18: 73.33%\n",
      "Epis√≥dio 19: 71.11%\n",
      "Epis√≥dio 20: 48.89%\n",
      "Epis√≥dio 21: 73.33%\n",
      "Epis√≥dio 22: 75.56%\n",
      "Epis√≥dio 23: 64.44%\n",
      "Epis√≥dio 24: 71.11%\n",
      "Epis√≥dio 25: 77.78%\n",
      "Epis√≥dio 26: 46.67%\n",
      "Epis√≥dio 27: 64.44%\n",
      "Epis√≥dio 28: 57.78%\n",
      "Epis√≥dio 29: 64.44%\n",
      "Epis√≥dio 30: 40.00%\n",
      "Epis√≥dio 31: 75.56%\n",
      "Epis√≥dio 32: 77.78%\n",
      "Epis√≥dio 33: 57.78%\n",
      "Epis√≥dio 34: 33.33%\n",
      "Epis√≥dio 35: 64.44%\n",
      "Epis√≥dio 36: 68.89%\n",
      "Epis√≥dio 37: 57.78%\n",
      "Epis√≥dio 38: 66.67%\n",
      "Epis√≥dio 39: 77.78%\n",
      "Epis√≥dio 40: 53.33%\n",
      "Epis√≥dio 41: 71.11%\n",
      "Epis√≥dio 42: 68.89%\n",
      "Epis√≥dio 43: 60.00%\n",
      "Epis√≥dio 44: 77.78%\n",
      "Epis√≥dio 45: 53.33%\n",
      "Epis√≥dio 46: 57.78%\n",
      "Epis√≥dio 47: 64.44%\n",
      "Epis√≥dio 48: 60.00%\n",
      "Epis√≥dio 49: 55.56%\n",
      "Epis√≥dio 50: 48.89%\n",
      "Epis√≥dio 51: 66.67%\n",
      "Epis√≥dio 52: 66.67%\n",
      "Epis√≥dio 53: 75.56%\n",
      "Epis√≥dio 54: 71.11%\n",
      "Epis√≥dio 55: 62.22%\n",
      "Epis√≥dio 56: 66.67%\n",
      "Epis√≥dio 57: 53.33%\n",
      "Epis√≥dio 58: 44.44%\n",
      "Epis√≥dio 59: 68.89%\n",
      "Epis√≥dio 60: 60.00%\n",
      "Epis√≥dio 61: 77.78%\n",
      "Epis√≥dio 62: 46.67%\n",
      "Epis√≥dio 63: 60.00%\n",
      "Epis√≥dio 64: 68.89%\n",
      "Epis√≥dio 65: 73.33%\n",
      "Epis√≥dio 66: 51.11%\n",
      "Epis√≥dio 67: 46.67%\n",
      "Epis√≥dio 68: 57.78%\n",
      "Epis√≥dio 69: 71.11%\n",
      "Epis√≥dio 70: 64.44%\n",
      "Epis√≥dio 71: 71.11%\n",
      "Epis√≥dio 72: 46.67%\n",
      "Epis√≥dio 73: 80.00%\n",
      "Epis√≥dio 74: 53.33%\n",
      "Epis√≥dio 75: 71.11%\n",
      "Epis√≥dio 76: 80.00%\n",
      "Epis√≥dio 77: 73.33%\n",
      "Epis√≥dio 78: 51.11%\n",
      "Epis√≥dio 79: 44.44%\n",
      "Epis√≥dio 80: 55.56%\n",
      "Epis√≥dio 81: 53.33%\n",
      "Epis√≥dio 82: 57.78%\n",
      "Epis√≥dio 83: 77.78%\n",
      "Epis√≥dio 84: 48.89%\n",
      "Epis√≥dio 85: 51.11%\n",
      "Epis√≥dio 86: 46.67%\n",
      "Epis√≥dio 87: 75.56%\n",
      "Epis√≥dio 88: 57.78%\n",
      "Epis√≥dio 89: 86.67%\n",
      "Epis√≥dio 90: 68.89%\n",
      "Epis√≥dio 91: 42.22%\n",
      "Epis√≥dio 92: 84.44%\n",
      "Epis√≥dio 93: 77.78%\n",
      "Epis√≥dio 94: 68.89%\n",
      "Epis√≥dio 95: 57.78%\n",
      "Epis√≥dio 96: 64.44%\n",
      "Epis√≥dio 97: 73.33%\n",
      "Epis√≥dio 98: 57.78%\n",
      "Epis√≥dio 99: 64.44%\n",
      "Epis√≥dio 100: 77.78%\n",
      "Epis√≥dio 101: 71.11%\n",
      "Epis√≥dio 102: 75.56%\n",
      "Epis√≥dio 103: 82.22%\n",
      "Epis√≥dio 104: 73.33%\n",
      "Epis√≥dio 105: 82.22%\n",
      "Epis√≥dio 106: 80.00%\n",
      "Epis√≥dio 107: 60.00%\n",
      "Epis√≥dio 108: 35.56%\n",
      "Epis√≥dio 109: 62.22%\n",
      "Epis√≥dio 110: 68.89%\n",
      "Epis√≥dio 111: 60.00%\n",
      "Epis√≥dio 112: 84.44%\n",
      "Epis√≥dio 113: 51.11%\n",
      "Epis√≥dio 114: 62.22%\n",
      "Epis√≥dio 115: 68.89%\n",
      "Epis√≥dio 116: 62.22%\n",
      "Epis√≥dio 117: 60.00%\n",
      "Epis√≥dio 118: 62.22%\n",
      "Epis√≥dio 119: 66.67%\n",
      "Epis√≥dio 120: 62.22%\n",
      "Epis√≥dio 121: 33.33%\n",
      "Epis√≥dio 122: 66.67%\n",
      "Epis√≥dio 123: 68.89%\n",
      "Epis√≥dio 124: 46.67%\n",
      "Epis√≥dio 125: 60.00%\n",
      "Epis√≥dio 126: 77.78%\n",
      "Epis√≥dio 127: 73.33%\n",
      "Epis√≥dio 128: 64.44%\n",
      "Epis√≥dio 129: 80.00%\n",
      "Epis√≥dio 130: 75.56%\n",
      "Epis√≥dio 131: 73.33%\n",
      "Epis√≥dio 132: 77.78%\n",
      "Epis√≥dio 133: 71.11%\n",
      "Epis√≥dio 134: 71.11%\n",
      "Epis√≥dio 135: 68.89%\n",
      "Epis√≥dio 136: 48.89%\n",
      "Epis√≥dio 137: 66.67%\n",
      "Epis√≥dio 138: 75.56%\n",
      "Epis√≥dio 139: 60.00%\n",
      "Epis√≥dio 140: 77.78%\n",
      "Epis√≥dio 141: 82.22%\n",
      "Epis√≥dio 142: 60.00%\n",
      "Epis√≥dio 143: 53.33%\n",
      "Epis√≥dio 144: 68.89%\n",
      "Epis√≥dio 145: 62.22%\n",
      "Epis√≥dio 146: 73.33%\n",
      "Epis√≥dio 147: 71.11%\n",
      "Epis√≥dio 148: 71.11%\n",
      "Epis√≥dio 149: 62.22%\n",
      "Epis√≥dio 150: 82.22%\n",
      "Epis√≥dio 151: 64.44%\n",
      "Epis√≥dio 152: 73.33%\n",
      "Epis√≥dio 153: 62.22%\n",
      "Epis√≥dio 154: 66.67%\n",
      "Epis√≥dio 155: 51.11%\n",
      "Epis√≥dio 156: 84.44%\n",
      "Epis√≥dio 157: 37.78%\n",
      "Epis√≥dio 158: 73.33%\n",
      "Epis√≥dio 159: 82.22%\n",
      "Epis√≥dio 160: 66.67%\n",
      "Epis√≥dio 161: 33.33%\n",
      "Epis√≥dio 162: 60.00%\n",
      "Epis√≥dio 163: 55.56%\n",
      "Epis√≥dio 164: 42.22%\n",
      "Epis√≥dio 165: 57.78%\n",
      "Epis√≥dio 166: 57.78%\n",
      "Epis√≥dio 167: 46.67%\n",
      "Epis√≥dio 168: 75.56%\n",
      "Epis√≥dio 169: 80.00%\n",
      "Epis√≥dio 170: 75.56%\n",
      "Epis√≥dio 171: 84.44%\n",
      "Epis√≥dio 172: 60.00%\n",
      "Epis√≥dio 173: 75.56%\n",
      "Epis√≥dio 174: 62.22%\n",
      "Epis√≥dio 175: 66.67%\n",
      "Epis√≥dio 176: 80.00%\n",
      "Epis√≥dio 177: 51.11%\n",
      "Epis√≥dio 178: 44.44%\n",
      "Epis√≥dio 179: 62.22%\n",
      "Epis√≥dio 180: 57.78%\n",
      "Epis√≥dio 181: 80.00%\n",
      "Epis√≥dio 182: 75.56%\n",
      "Epis√≥dio 183: 84.44%\n",
      "Epis√≥dio 184: 60.00%\n",
      "Epis√≥dio 185: 57.78%\n",
      "Epis√≥dio 186: 46.67%\n",
      "Epis√≥dio 187: 60.00%\n",
      "Epis√≥dio 188: 80.00%\n",
      "Epis√≥dio 189: 57.78%\n",
      "Epis√≥dio 190: 62.22%\n",
      "Epis√≥dio 191: 80.00%\n",
      "Epis√≥dio 192: 84.44%\n",
      "Epis√≥dio 193: 37.78%\n",
      "Epis√≥dio 194: 75.56%\n",
      "Epis√≥dio 195: 77.78%\n",
      "Epis√≥dio 196: 57.78%\n",
      "Epis√≥dio 197: 68.89%\n",
      "Epis√≥dio 198: 73.33%\n",
      "Epis√≥dio 199: 73.33%\n",
      "Epis√≥dio 200: 53.33%\n",
      "\n",
      "Acur√°cia final: 65.00% ¬± 12.21%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "accuracies = []\n",
    "# Labels remapeados (para cada epis√≥dio independente)\n",
    "all_predictions_remapped = []\n",
    "all_labels_remapped = []\n",
    "# Labels originais (classes reais do dataset)\n",
    "all_predictions_original = []\n",
    "all_labels_original = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for ep in range(CONFIG['n_episodes']):\n",
    "    acc, preds_remapped, labels_remapped, preds_original, labels_original = evaluate_episode(\n",
    "        model,\n",
    "        dataset,\n",
    "        class_to_indices,\n",
    "        CONFIG['device'],\n",
    "        n_way=CONFIG['n_way'],\n",
    "        n_shot=CONFIG['n_shot'],\n",
    "        n_query=CONFIG['n_query']\n",
    "    )\n",
    "    accuracies.append(acc)\n",
    "    # Armazenar ambas as vers√µes\n",
    "    all_predictions_remapped.extend(preds_remapped)\n",
    "    all_labels_remapped.extend(labels_remapped)\n",
    "    all_predictions_original.extend(preds_original)\n",
    "    all_labels_original.extend(labels_original)\n",
    "    print(f\"Epis√≥dio {ep+1}: {acc*100:.2f}%\")\n",
    "\n",
    "mean_acc = np.mean(accuracies)\n",
    "std_acc  = np.std(accuracies)\n",
    "\n",
    "print(f\"\\nAcur√°cia final: {mean_acc*100:.2f}% ¬± {std_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a77d8",
   "metadata": {},
   "source": [
    "## üìä Por que Precision = Recall = F1 = Acur√°cia?\n",
    "\n",
    "**Problema:** Quando os labels s√£o **remapeados** para [0, 1, 2] em cada epis√≥dio:\n",
    "- Epis√≥dio 1: [melanoma=0, nevo=1, ceratose=2]\n",
    "- Epis√≥dio 2: [nevo=0, basalioma=1, melanoma=2]  \n",
    "- Epis√≥dio 3: [ceratose=0, melanoma=1, dermatofibroma=2]\n",
    "\n",
    "Ao agregar 200 epis√≥dios, cada slot [0, 1, 2] recebe uma **distribui√ß√£o uniforme** de todas as classes reais. Com amostragem aleat√≥ria, a matriz de confus√£o fica balanceada e **todas as m√©tricas convergem para o mesmo valor**!\n",
    "\n",
    "**Solu√ß√£o:** Manter os **labels originais** (classes reais) para calcular m√©tricas que fazem sentido sem√¢ntico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d870b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPARA√á√ÉO DE M√âTRICAS:\n",
      "============================================================\n",
      "\n",
      "1. M√©tricas com labels REMAPEADOS (cada epis√≥dio = [0,1,2]):\n",
      "   (Labels perdem significado sem√¢ntico - n√£o recomendado!)\n",
      "   Precision (macro): 65.00%\n",
      "   Recall (macro):    65.00%\n",
      "   F1-Score (macro):  64.99%\n",
      "   Acur√°cia:          65.00%\n",
      "   ‚Üí Todas iguais! N√£o t√™m significado real.\n",
      "\n",
      "2. M√©tricas com labels ORIGINAIS (classes reais do dataset):\n",
      "   (M√©tricas por classe real - correto!)\n",
      "   Precision (macro): 64.60%\n",
      "   Recall (macro):    64.90%\n",
      "   F1-Score (macro):  64.64%\n",
      "   Acur√°cia:          65.00%\n",
      "   ‚Üí Valores diferentes! Fazem sentido sem√¢ntico.\n",
      "\n",
      "3. Acur√°cia m√©dia dos epis√≥dios (m√©todo padr√£o few-shot):\n",
      "   Acur√°cia:  65.00% ¬± 12.21%\n",
      "   ‚Üí M√©trica correta para few-shot epis√≥dico!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "M√âTRICAS DETALHADAS POR CLASSE (Labels Originais):\n",
      "============================================================\n",
      "\n",
      "Classes do dataset: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec     0.7003    0.7364    0.7179      1320\n",
      "         bcc     0.5820    0.5663    0.5740      1335\n",
      "         bkl     0.5591    0.5292    0.5437      1440\n",
      "          df     0.5862    0.5483    0.5666      1005\n",
      "         mel     0.5934    0.6407    0.6161      1230\n",
      "          nv     0.7857    0.8837    0.8318      1290\n",
      "        vasc     0.7157    0.6384    0.6748      1380\n",
      "\n",
      "    accuracy                         0.6500      9000\n",
      "   macro avg     0.6460    0.6490    0.6464      9000\n",
      "weighted avg     0.6474    0.6500    0.6476      9000\n",
      "\n",
      "============================================================\n",
      "\n",
      "======================================================================\n",
      "Resultados salvos em: /content/drive/MyDrive/pdi/resultados/deit_prototypical_fewshot_3way_5shot_200ep_v2\n",
      "======================================================================\n",
      "Configura√ß√£o: 3-way 5-shot (200 epis√≥dios)\n",
      "Acur√°cia: 65.00% ¬± 12.21%\n",
      "Precision (macro): 64.60%\n",
      "Recall (macro): 64.90%\n",
      "F1-Score (macro): 64.64%\n",
      "\n",
      "Arquivos gerados:\n",
      "  - config.json\n",
      "  - report.txt\n",
      "  - per_class_metrics.json\n",
      "  - per_class_report.txt\n",
      "  - metrics_table.png\n",
      "  - confusion_matrix.png\n",
      "  - predictions.json\n",
      "  - accuracy_per_episode.png\n",
      "  - accuracy_distribution.png\n",
      "  - accuracy_boxplot.png\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Converter para arrays\n",
    "all_predictions_remapped = np.array(all_predictions_remapped)\n",
    "all_labels_remapped = np.array(all_labels_remapped)\n",
    "all_predictions_original = np.array(all_predictions_original)\n",
    "all_labels_original = np.array(all_labels_original)\n",
    "\n",
    "\n",
    "# Obter nomes das classes do dataset\n",
    "class_names = dataset.classes\n",
    "\n",
    "# Salvar resultados usando as classes ORIGINAIS + nomes das classes\n",
    "exp_dir = save_fewshot_results(\n",
    "    experiment_name=\"deit_prototypical_fewshot\",\n",
    "    model_name=CONFIG['model_name'],\n",
    "    metric_name=\"Similaridade Cosine\",\n",
    "    normalization=\"Normalizacao L2\",\n",
    "    accuracies=accuracies,\n",
    "    n_way=CONFIG['n_way'],\n",
    "    n_shot=CONFIG['n_shot'],\n",
    "    n_query=CONFIG['n_query'],\n",
    "    n_episodes=CONFIG['n_episodes'],\n",
    "    device=CONFIG['device'],\n",
    "    all_predictions=all_predictions_original, \n",
    "    all_labels=all_labels_original,             \n",
    "    class_names=class_names                     \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
