{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bbde0d9",
   "metadata": {},
   "source": [
    "# Avaliação Few-Shot com Aprendizado Episódico\n",
    "\n",
    "Este notebook implementa uma avaliação few-shot usando aprendizado episódico com redes de protótipos e um modelo Vision Transformer (DeiT) pré-treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "importlib.reload(__import__('helpers'))\n",
    "from helpers import save_fewshot_results\n",
    "import timm\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768eb0ee",
   "metadata": {},
   "source": [
    "## 1. Configuração do Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f909b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'n_way': 3,\n",
    "    'n_shot': 5,\n",
    "    'n_query': 15,\n",
    "    'n_episodes': 200,\n",
    "    'model_name': 'deit_base_distilled_patch16_224',\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eadc8ed",
   "metadata": {},
   "source": [
    "## 2. Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc25e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],   \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f3ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "    root=OUT_PATH,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "class_to_indices = defaultdict(list)\n",
    "for idx, (_, label) in enumerate(dataset):\n",
    "    class_to_indices[label].append(idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e753d1d",
   "metadata": {},
   "source": [
    "## 3. Funções Auxiliares para Episódios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5277e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_episode(\n",
    "    class_to_indices,\n",
    "    n_way=5,\n",
    "    n_shot=10,\n",
    "    n_query=15\n",
    "):\n",
    "    classes = random.sample(list(class_to_indices.keys()), n_way)\n",
    "\n",
    "    support_idx = []\n",
    "    query_idx = []\n",
    "\n",
    "    for c in classes:\n",
    "        indices = random.sample(\n",
    "            class_to_indices[c],\n",
    "            n_shot + n_query\n",
    "        )\n",
    "        support_idx += indices[:n_shot]\n",
    "        query_idx   += indices[n_shot:]\n",
    "\n",
    "    return support_idx, query_idx, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_loaders(dataset, support_idx, query_idx):\n",
    "    support_loader = DataLoader(\n",
    "        Subset(dataset, support_idx),\n",
    "        batch_size=len(support_idx),\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    query_loader = DataLoader(\n",
    "        Subset(dataset, query_idx),\n",
    "        batch_size=len(query_idx),\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return support_loader, query_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebe2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_vit(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = imgs.to(next(model.parameters()).device)\n",
    "            feats = model(imgs)\n",
    "            features.append(feats)\n",
    "            labels.append(lbls)\n",
    "\n",
    "    return torch.cat(features), torch.cat(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e37d9e",
   "metadata": {},
   "source": [
    "## 4. Implementação da Rede de Protótipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e83f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(\n",
    "    model,\n",
    "    dataset,\n",
    "    class_to_indices,\n",
    "    device,\n",
    "    n_way=5,\n",
    "    n_shot=10,\n",
    "    n_query=15\n",
    "):\n",
    "    support_idx, query_idx, classes = create_episode(\n",
    "        class_to_indices, n_way, n_shot, n_query\n",
    "    )\n",
    "\n",
    "    support_loader, query_loader = get_episode_loaders(\n",
    "        dataset, support_idx, query_idx\n",
    "    )\n",
    "\n",
    "    support_features, support_labels = extract_features_vit(\n",
    "        support_loader, model\n",
    "    )\n",
    "    query_features, query_labels = extract_features_vit(\n",
    "        query_loader, model\n",
    "    )\n",
    "\n",
    "    original_query_labels = query_labels.cpu().numpy()\n",
    "\n",
    "    support_features = F.normalize(support_features, p=2, dim=1)\n",
    "    query_features   = F.normalize(query_features, p=2, dim=1)\n",
    "\n",
    "    label_map = {c: i for i, c in enumerate(classes)}\n",
    "    support_labels = torch.tensor(\n",
    "        [label_map[int(l)] for l in support_labels],\n",
    "        device=device\n",
    "    )\n",
    "    query_labels_remapped = torch.tensor(\n",
    "        [label_map[int(l)] for l in query_labels],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    prototypes = torch.zeros(n_way, support_features.size(1)).to(device)\n",
    "    for i in range(n_way):\n",
    "        prototypes[i] = support_features[support_labels == i].mean(0)\n",
    "    \n",
    "    prototypes = F.normalize(prototypes, p=2, dim=1)\n",
    "\n",
    "    sims = torch.mm(query_features, prototypes.t())\n",
    "    preds_remapped = sims.argmax(dim=1)\n",
    "\n",
    "    acc = (preds_remapped == query_labels_remapped).float().mean().item()\n",
    "    \n",
    "    original_preds = np.array([classes[int(p)] for p in preds_remapped.cpu().numpy()])\n",
    "    \n",
    "    return acc, preds_remapped.cpu().numpy(), query_labels_remapped.cpu().numpy(), original_preds, original_query_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad479eb3",
   "metadata": {},
   "source": [
    "## 5. Carregamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    CONFIG['model_name'],\n",
    "    pretrained=True,\n",
    "    num_classes=0\n",
    ")\n",
    "\n",
    "model = model.to(CONFIG['device'])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35d6fb",
   "metadata": {},
   "source": [
    "## 6. Avaliação Episódica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d428ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "all_predictions_remapped = []\n",
    "all_labels_remapped = []\n",
    "all_predictions_original = []\n",
    "all_labels_original = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for ep in range(CONFIG['n_episodes']):\n",
    "    acc, preds_remapped, labels_remapped, preds_original, labels_original = evaluate_episode(\n",
    "        model,\n",
    "        dataset,\n",
    "        class_to_indices,\n",
    "        CONFIG['device'],\n",
    "        n_way=CONFIG['n_way'],\n",
    "        n_shot=CONFIG['n_shot'],\n",
    "        n_query=CONFIG['n_query']\n",
    "    )\n",
    "    accuracies.append(acc)\n",
    "    all_predictions_remapped.extend(preds_remapped)\n",
    "    all_labels_remapped.extend(labels_remapped)\n",
    "    all_predictions_original.extend(preds_original)\n",
    "    all_labels_original.extend(labels_original)\n",
    "    print(f\"Episódio {ep+1}: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c268739",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = np.mean(accuracies)\n",
    "std_acc  = np.std(accuracies)\n",
    "\n",
    "print(f\"\\nAcurácia final: {mean_acc*100:.2f}% ± {std_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f767bf12",
   "metadata": {},
   "source": [
    "## 7. Salvamento dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d870b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_remapped = np.array(all_predictions_remapped)\n",
    "all_labels_remapped = np.array(all_labels_remapped)\n",
    "all_predictions_original = np.array(all_predictions_original)\n",
    "all_labels_original = np.array(all_labels_original)\n",
    "\n",
    "class_names = dataset.classes\n",
    "\n",
    "exp_dir = save_fewshot_results(\n",
    "    experiment_name=\"deit_prototypical_fewshot\",\n",
    "    model_name=CONFIG['model_name'],\n",
    "    metric_name=\"Similaridade Cosine\",\n",
    "    normalization=\"Normalizacao L2\",\n",
    "    accuracies=accuracies,\n",
    "    n_way=CONFIG['n_way'],\n",
    "    n_shot=CONFIG['n_shot'],\n",
    "    n_query=CONFIG['n_query'],\n",
    "    n_episodes=CONFIG['n_episodes'],\n",
    "    device=CONFIG['device'],\n",
    "    all_predictions=all_predictions_original, \n",
    "    all_labels=all_labels_original,             \n",
    "    class_names=class_names                     \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
