{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3e067b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c098ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],   \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ade5760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    root='/content/dataset/ham10000/train',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root='/content/dataset/ham10000/test',\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38eb7968",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20a2d5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['akiec', 'bcc', 'bkl', 'mel', 'nv']\n",
      "Número de imagens treino: 25\n",
      "Número de imagens teste: 75\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes:\", train_dataset.classes)\n",
    "print(\"Número de imagens treino:\", len(train_dataset))\n",
    "print(\"Número de imagens teste:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ebc4ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando Vision Transformer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b82d69b39c4d708ff32a7ccd07802a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo features com ViT...\n",
      "\n",
      "============================================================\n",
      "Acurácia ViT + Prototypical Networks: 26.67%\n",
      "============================================================\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec      0.400     0.267     0.320        15\n",
      "         bcc      0.318     0.467     0.378        15\n",
      "         bkl      0.286     0.133     0.182        15\n",
      "         mel      0.238     0.333     0.278        15\n",
      "          nv      0.133     0.133     0.133        15\n",
      "\n",
      "    accuracy                          0.267        75\n",
      "   macro avg      0.275     0.267     0.258        75\n",
      "weighted avg      0.275     0.267     0.258        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estratégia baseada em Nurgazin et al. (2023): ViT + ProtoNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import timm  # Biblioteca para Vision Transformers\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 1. Carregar Vision Transformer pré-treinado (melhor que ResNet para FSL)\n",
    "print(\"Carregando Vision Transformer...\")\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=0)  # num_classes=0 remove última camada\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "# 2. Extrair features\n",
    "def extract_features_vit(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            feats = model(imgs)  # ViT retorna features globais\n",
    "            features.append(feats)\n",
    "            labels.append(lbls.to(device))\n",
    "    \n",
    "    return torch.cat(features), torch.cat(labels)\n",
    "\n",
    "print(\"Extraindo features com ViT...\")\n",
    "support_features, support_labels = extract_features_vit(train_loader, model)\n",
    "query_features, query_labels = extract_features_vit(test_loader, model)\n",
    "\n",
    "# 3. Normalização L2 (crucial para similaridade métrica)\n",
    "support_features = F.normalize(support_features, p=2, dim=1)\n",
    "query_features = F.normalize(query_features, p=2, dim=1)\n",
    "\n",
    "# 4. Calcular protótipos com normalização\n",
    "num_classes = len(train_dataset.classes)\n",
    "prototypes = torch.zeros(num_classes, support_features.size(1)).to(device)\n",
    "\n",
    "for c in range(num_classes):\n",
    "    mask = (support_labels == c)\n",
    "    if mask.sum() > 0:\n",
    "        class_features = support_features[mask]\n",
    "        prototypes[c] = class_features.mean(dim=0)\n",
    "        # Normalizar cada protótipo\n",
    "        prototypes[c] = F.normalize(prototypes[c].unsqueeze(0), p=2, dim=1).squeeze(0)\n",
    "\n",
    "# 5. Classificação por SIMILARIDADE COSINE (produto escalar com vetores normalizados)\n",
    "# Mais adequado que distância euclidiana para features normalizadas\n",
    "similarities = torch.mm(query_features, prototypes.t())  \n",
    "predictions = similarities.argmax(dim=1)\n",
    "\n",
    "# 6. Avaliar\n",
    "accuracy = (predictions == query_labels).float().mean().item()\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'Acurácia ViT + Prototypical Networks: {accuracy*100:.2f}%')\n",
    "print(f'{\"=\"*60}')\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(\n",
    "    query_labels.cpu().numpy(), \n",
    "    predictions.cpu().numpy(),\n",
    "    target_names=train_dataset.classes,\n",
    "    digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
