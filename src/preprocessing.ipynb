{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d3e067b3",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "importlib.reload(__import__('helpers'))\n",
    "from helpers import save_experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098ed85",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],   \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade5760e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    root='/content/dataset/ham10000/train',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root='/content/dataset/ham10000/test',\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "38eb7968",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=25,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=75,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "20a2d5f1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['akiec', 'bcc', 'bkl', 'mel', 'nv']\n",
      "Número de imagens treino: 50\n",
      "Número de imagens teste: 250\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes:\", train_dataset.classes)\n",
    "print(\"Número de imagens treino:\", len(train_dataset))\n",
    "print(\"Número de imagens teste:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebc4ba6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando DeiT...\n",
      "Extraindo features com ViT...\n",
      "\n",
      "============================================================\n",
      "Acurácia DeiT + Prototypical Networks: 50.00%\n",
      "============================================================\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec      0.562     0.540     0.551        50\n",
      "         bcc      0.550     0.660     0.600        50\n",
      "         bkl      0.256     0.200     0.225        50\n",
      "         mel      0.434     0.460     0.447        50\n",
      "          nv      0.640     0.640     0.640        50\n",
      "\n",
      "    accuracy                          0.500       250\n",
      "   macro avg      0.489     0.500     0.492       250\n",
      "weighted avg      0.489     0.500     0.492       250\n",
      "\n",
      "\n",
      "============================================================\n",
      "Resultados salvos em: /content/drive/MyDrive/pdi/resultados/deit_cosine_similarity_5way_10shot_v2\n",
      "============================================================\n",
      "Configuração: 5-way 10-shot\n",
      "Arquivos gerados:\n",
      "  - config.json\n",
      "  - metrics.json\n",
      "  - report.txt\n",
      "  - confusion_matrix.png\n",
      "  - accuracy_per_class.png\n",
      "  - predictions.json\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estratégia baseada em Nurgazin et al. (2023): ViT + ProtoNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import timm  # Biblioteca para Vision Transformers\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "experiment_name = \"deit_cosine_similarity\"\n",
    "\n",
    "\n",
    "# 1. Carregar Vision Transformer pré-treinado (melhor que ResNet para FSL)\n",
    "print(\"Carregando DeiT...\")\n",
    "model = timm.create_model('deit_base_distilled_patch16_224', pretrained=True, num_classes=0)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "# 2. Extrair features\n",
    "def extract_features_vit(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            feats = model(imgs)  # ViT retorna features globais\n",
    "            features.append(feats)\n",
    "            labels.append(lbls.to(device))\n",
    "    \n",
    "    return torch.cat(features), torch.cat(labels)\n",
    "\n",
    "print(\"Extraindo features com ViT...\")\n",
    "support_features, support_labels = extract_features_vit(train_loader, model)\n",
    "query_features, query_labels = extract_features_vit(test_loader, model)\n",
    "\n",
    "# 3. Normalização L2 (crucial para similaridade métrica)\n",
    "support_features = F.normalize(support_features, p=2, dim=1)\n",
    "query_features = F.normalize(query_features, p=2, dim=1)\n",
    "\n",
    "# 4. Calcular protótipos com normalização\n",
    "num_classes = len(train_dataset.classes)\n",
    "prototypes = torch.zeros(num_classes, support_features.size(1)).to(device)\n",
    "\n",
    "for c in range(num_classes):\n",
    "    mask = (support_labels == c)\n",
    "    if mask.sum() > 0:\n",
    "        class_features = support_features[mask]\n",
    "        prototypes[c] = class_features.mean(dim=0)\n",
    "        # Normalizar cada protótipo\n",
    "        prototypes[c] = F.normalize(prototypes[c].unsqueeze(0), p=2, dim=1).squeeze(0)\n",
    "\n",
    "# 5. Classificação por SIMILARIDADE COSINE (produto escalar com vetores normalizados)\n",
    "# Mais adequado que distância euclidiana para features normalizadas\n",
    "similarities = torch.mm(query_features, prototypes.t())  \n",
    "predictions_deit = similarities.argmax(dim=1)\n",
    "\n",
    "# 6. Avaliar\n",
    "accuracy = (predictions_deit == query_labels).float().mean().item()\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'Acurácia DeiT + Prototypical Networks: {accuracy*100:.2f}%')\n",
    "print(f'{\"=\"*60}')\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(\n",
    "    query_labels.cpu().numpy(), \n",
    "    predictions_deit.cpu().numpy(),\n",
    "    target_names=train_dataset.classes,\n",
    "    digits=3\n",
    "))\n",
    "\n",
    "# 7. SALVAR RESULTADOS\n",
    "exp_dir = save_experiment_results(\n",
    "    experiment_name=experiment_name,\n",
    "    model_name=\"DeiT Base Distilled Patch16 224\",\n",
    "    metric_name=\"Similaridade Cosine\",\n",
    "    normalization=\"Normalizacao L2\",\n",
    "    y_true=query_labels.cpu().numpy(),\n",
    "    y_pred=predictions_deit.cpu().numpy(),\n",
    "    class_names=train_dataset.classes,\n",
    "    n_train=len(train_dataset),\n",
    "    n_test=len(test_dataset),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "38db46f8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando ResNet50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo features com ResNet50...\n",
      "\n",
      "============================================================\n",
      "Acurácia ResNet50 + Distância Euclidiana: 46.80%\n",
      "============================================================\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec      0.580     0.580     0.580        50\n",
      "         bcc      0.492     0.620     0.549        50\n",
      "         bkl      0.300     0.180     0.225        50\n",
      "         mel      0.354     0.340     0.347        50\n",
      "          nv      0.525     0.620     0.569        50\n",
      "\n",
      "    accuracy                          0.468       250\n",
      "   macro avg      0.450     0.468     0.454       250\n",
      "weighted avg      0.450     0.468     0.454       250\n",
      "\n",
      "\n",
      "============================================================\n",
      "Resultados salvos em: /content/drive/MyDrive/pdi/resultados/resnet50_euclidiana_5way_10shot_v4\n",
      "============================================================\n",
      "Configuração: 5-way 10-shot\n",
      "Arquivos gerados:\n",
      "  - config.json\n",
      "  - metrics.json\n",
      "  - report.txt\n",
      "  - confusion_matrix.png\n",
      "  - accuracy_per_class.png\n",
      "  - predictions.json\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Voltar para ResNet50 + Distância Euclidiana + SALVAR RESULTADOS\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Nome do experimento\n",
    "experiment_name = \"resnet50_euclidiana\"\n",
    "\n",
    "\n",
    "# 1. Carregar ResNet50 pré-treinada\n",
    "print(\"Carregando ResNet50...\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Identity()  # Remove última camada (só features)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "# 2. Extrair features\n",
    "def extract_features_resnet(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            feats = model(imgs)\n",
    "            features.append(feats)\n",
    "            labels.append(lbls.to(device))\n",
    "    \n",
    "    return torch.cat(features), torch.cat(labels)\n",
    "\n",
    "print(\"Extraindo features com ResNet50...\")\n",
    "support_features, support_labels = extract_features_resnet(train_loader, model)\n",
    "query_features, query_labels = extract_features_resnet(test_loader, model)\n",
    "\n",
    "\n",
    "# 3. Calcular protótipos (SEM normalização L2)\n",
    "num_classes = len(train_dataset.classes)\n",
    "prototypes = torch.zeros(num_classes, support_features.size(1)).to(device)\n",
    "\n",
    "for c in range(num_classes):\n",
    "    mask = (support_labels == c)\n",
    "    if mask.sum() > 0:\n",
    "        class_features = support_features[mask]\n",
    "        prototypes[c] = class_features.mean(dim=0)  # Média simples\n",
    "\n",
    "# 4. Classificação por DISTÂNCIA EUCLIDIANA\n",
    "distances = torch.cdist(query_features, prototypes)  # Distância euclidiana\n",
    "predictions_resnet = distances.argmin(dim=1)  # Classe com menor distância\n",
    "\n",
    "# 5. Avaliar\n",
    "accuracy = (predictions_resnet == query_labels).float().mean().item()\n",
    "y_true = query_labels.cpu().numpy()\n",
    "y_pred = predictions_resnet.cpu().numpy()\n",
    "\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'Acurácia ResNet50 + Distância Euclidiana: {accuracy*100:.2f}%')\n",
    "print(f'{\"=\"*60}')\n",
    "\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(\n",
    "    y_true, \n",
    "    y_pred,\n",
    "    target_names=train_dataset.classes,\n",
    "    digits=3\n",
    "))\n",
    "\n",
    "# 7. SALVAR RESULTADOS\n",
    "exp_dir = save_experiment_results(\n",
    "    experiment_name=experiment_name,\n",
    "    model_name=\"ResNet50\",\n",
    "    metric_name=\"Distancia Euclidiana\",\n",
    "    normalization=\"Sem normalizacao L2\",\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred,\n",
    "    class_names=train_dataset.classes,\n",
    "    n_train=len(train_dataset),\n",
    "    n_test=len(test_dataset),\n",
    "    device=device\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
